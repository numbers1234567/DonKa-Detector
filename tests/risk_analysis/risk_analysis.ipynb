{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Analysis for DonKa Detector\n",
    "\n",
    "Initial tests to determine potential challenges for the DonKa Detector\n",
    "\n",
    "## Assessments\n",
    "\n",
    " 1. Options for audio streaming\n",
    " 2. Optimizing for Digital Signal Processing (DSP)\n",
    "    1. Might want to pivot away from Python. \n",
    "    2. First, see how intensive operations are involving NumPy\n",
    " 3. High-accuracy detection options\n",
    "    1. Create datasets of pencil taps and Tatacon usage\n",
    "    2. Detection using statistics\n",
    "       1. Quantile analysis of the DFT\n",
    "       2. Mean/Median-based detectuib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Options for audio streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import math\n",
    "\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100\n",
    "CHUNK = 512\n",
    "RECORD_SECONDS = 5\n",
    "WAVE_OUTPUT_FILENAME = \"recordedFile.wav\"\n",
    "device_index = 2\n",
    "audio = pyaudio.PyAudio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = audio.get_host_api_info_by_index(0)\n",
    "numdevices = info.get('deviceCount')\n",
    "for i in range(0, numdevices):\n",
    "        if (audio.get_device_info_by_host_api_device_index(0, i).get('maxInputChannels')) > 0:\n",
    "            print(\"Input Device id \", i, \" - \", audio.get_device_info_by_host_api_device_index(0, i).get('name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "device_index = 2\n",
    "stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                rate=RATE, input=True,input_device_index = device_index,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "Recordframes = []\n",
    " \n",
    "for i in range(0, math.ceil(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    Recordframes.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "waveFile.setnchannels(CHANNELS)\n",
    "waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "waveFile.setframerate(RATE)\n",
    "waveFile.writeframes(b''.join(Recordframes))\n",
    "waveFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Options for DSP\n",
    "\n",
    "Use the same setup as for assessment (1), but see how quickly we can perform operations using NumPy and librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessment of NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import math\n",
    "\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "CHUNK = 4096\n",
    "RECORD_SECONDS = 5\n",
    "WAVE_OUTPUT_FILENAME = \"recordedFile.wav\"\n",
    "device_index = 2\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "info = audio.get_host_api_info_by_index(0)\n",
    "numdevices = info.get('deviceCount')\n",
    "for i in range(0, numdevices):\n",
    "        if (audio.get_device_info_by_host_api_device_index(0, i).get('maxInputChannels')) > 0:\n",
    "            print(\"Input Device id \", i, \" - \", audio.get_device_info_by_host_api_device_index(0, i).get('name'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can play around with different rates and chunk sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "device_index = 2\n",
    "stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                rate=RATE, input=True,input_device_index = device_index,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "audio_arr = np.zeros((RATE, ))\n",
    "np_time = 0\n",
    " \n",
    "for i in range(0, math.ceil(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    start=time.time()\n",
    "    # Shift Audio array\n",
    "    audio_arr[:-CHUNK] = audio_arr[CHUNK:]\n",
    "    audio_arr[-CHUNK:] = np.frombuffer(data, dtype=np.int16)\n",
    "    np_time += time.time()-start\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    "\n",
    "np_time/RECORD_SECONDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(audio_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessment of Librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import math\n",
    "\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "CHUNK = 2048\n",
    "RECORD_SECONDS = 5\n",
    "WAVE_OUTPUT_FILENAME = \"recordedFile.wav\"\n",
    "device_index = 2\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "info = audio.get_host_api_info_by_index(0)\n",
    "numdevices = info.get('deviceCount')\n",
    "for i in range(0, numdevices):\n",
    "        if (audio.get_device_info_by_host_api_device_index(0, i).get('maxInputChannels')) > 0:\n",
    "            print(\"Input Device id \", i, \" - \", audio.get_device_info_by_host_api_device_index(0, i).get('name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import librosa.onset\n",
    "\n",
    "device_index = 2\n",
    "stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                rate=RATE, input=True,input_device_index = device_index,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "audio_arr = np.zeros((RATE*RECORD_SECONDS + CHUNK, ))\n",
    "onsets = np.array([audio_arr.shape[0]-1])\n",
    "np_time,librosa_time = 0,0\n",
    " \n",
    "for i in range(0, math.ceil(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    start=time.time()\n",
    "    # Shift Audio array\n",
    "    audio_arr[:-CHUNK] = audio_arr[CHUNK:]\n",
    "    audio_arr[-CHUNK:] = np.frombuffer(data, dtype=np.int16)\n",
    "    np_time += time.time()-start\n",
    "    onsets -= CHUNK\n",
    "\n",
    "    # Librosa onsets\n",
    "    this_audio = audio_arr[onsets[-1]:]\n",
    "    if np.max(np.abs(this_audio)) < 500: continue\n",
    "\n",
    "    start = time.time()\n",
    "    this_onsets = librosa.onset.onset_detect(y=this_audio, sr=RATE, units=\"samples\")\n",
    "    librosa_time += time.time() - start\n",
    "\n",
    "    onsets = np.concatenate((onsets, this_onsets+onsets[-1]))\n",
    "\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    "\n",
    "np_time/RECORD_SECONDS,librosa_time/RECORD_SECONDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.onset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot([i/RATE for i in range(audio_arr.shape[0])],audio_arr)\n",
    "plt.plot(onsets/RATE, [0]*len(onsets), 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "donka-detector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
